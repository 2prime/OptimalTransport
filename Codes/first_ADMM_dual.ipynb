{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !Convert*first_ADMM_dual.py*w*sh*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init(m, n, c):\n",
    "    lamda = numpy.zeros(m)\n",
    "    eta = numpy.zeros(n)\n",
    "    \n",
    "    e = c - lamda.reshape((m, 1)) - eta.reshape((1, n))\n",
    "    d = numpy.zeros((m, n))\n",
    "    \n",
    "    return lamda, eta, e, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(m, n, mu, nu, c, lamda, eta, e, d, eta_sigma, rho, alpha):\n",
    "    lamda = (\n",
    "          (mu + numpy.sum(d, axis=1)) / rho\n",
    "        - eta_sigma\n",
    "        - numpy.sum(e, axis=1)\n",
    "        + numpy.sum(c, axis=1)\n",
    "    ) / n\n",
    "    \n",
    "    lamda_sigma = numpy.sum(lamda)\n",
    "    \n",
    "    eta = (\n",
    "          (nu + numpy.sum(d, axis=0)) / rho\n",
    "        - lamda_sigma\n",
    "        - numpy.sum(e, axis=0)\n",
    "        + numpy.sum(c, axis=0)\n",
    "    ) / m\n",
    "    \n",
    "    e = d + c - lamda.reshape((m, 1)) - eta.reshape((1, n))\n",
    "    e = numpy.maximum(e, 0.)\n",
    "    \n",
    "    d = d + alpha * rho * (c - lamda.reshape((m, 1)) - eta.reshape((1, n)) - e)\n",
    "    \n",
    "    return lamda, eta, e, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_ADMM_dual(\n",
    "    p,\n",
    "    scale=None, its=[], rhos=[], alphas=[], epss=None, min_its=None,\n",
    "    fh=None, figs={}, log=None, stat=False,\n",
    "    *args, **kwargs\n",
    "):\n",
    "    m, n = p.c.shape\n",
    "    \n",
    "    if scale is None:\n",
    "        scale = math.sqrt(m * n)\n",
    "    \n",
    "    mu, nu = scale*p.mu, scale*p.nu\n",
    "    c = p.c\n",
    "    \n",
    "    if fh is not None:\n",
    "        if \"error\" in figs:\n",
    "            error_e = []\n",
    "            error_mu = []\n",
    "            error_nu = []\n",
    "        if \"loss\" in figs:\n",
    "            loss_dual = []\n",
    "            loss_dual2 = []\n",
    "    \n",
    "    lamda, eta, e, d = init(m, n, c)\n",
    "    \n",
    "    l = len(its)\n",
    "    itc = 0\n",
    "    \n",
    "    for i in range(l):\n",
    "        for j in range(its[i]):\n",
    "            lamda, eta, e, d = update(m, n, mu, nu, c, lamda, eta, e, d, 0., rhos[i], alphas[i])\n",
    "\n",
    "            itc += 1\n",
    "\n",
    "            if fh is not None:\n",
    "                if \"error\" in figs:\n",
    "                    error_mu.append(numpy.linalg.norm(d.sum(axis=1) + mu, numpy.infty) / scale * m)\n",
    "                    error_nu.append(numpy.linalg.norm(d.sum(axis=0) + nu, numpy.infty) / scale * n)\n",
    "                    error_e.append(numpy.linalg.norm(c - lamda.reshape((m, 1)) - eta.reshape((1, n)) - e))\n",
    "                if \"loss\" in figs:\n",
    "                    loss_dual.append(-((c * d).sum() / scale))\n",
    "                    loss_dual2.append(((lamda * mu).sum() + (eta * nu).sum()) / scale)\n",
    "            if epss is not None:\n",
    "                if (\n",
    "                        numpy.linalg.norm(d.sum(axis=1) + mu, numpy.infty) / scale * m < epss[i]\n",
    "                    and numpy.linalg.norm(d.sum(axis=0) + nu, numpy.infty) / scale * n < epss[i]\n",
    "                ):\n",
    "                    if min_its is None or j > min_its[i]:\n",
    "                        break\n",
    "                    \n",
    "            if log is not None:\n",
    "                log(\"i, j, itc = {0}, {1}, {2}\".format(i, j, itc))\n",
    "    \n",
    "    # To save time\n",
    "    p.s = d / (-scale)\n",
    "    \n",
    "    if fh is not None:\n",
    "        if \"error\" in figs:\n",
    "            fh.new(1, 1, 1)\n",
    "            fh.ax.semilogy(numpy.array(error_mu), label=\"Error of mu\")\n",
    "            fh.ax.semilogy(numpy.array(error_nu), label=\"Error of nu\")\n",
    "            fh.ax.semilogy(numpy.array(error_e), label=\"Error of e\")\n",
    "            fh.ax.legend()\n",
    "            fh.show()\n",
    "            fh.close()\n",
    "        if \"loss\" in figs:\n",
    "            fh.new(1, 1, 1)\n",
    "            fh.ax.plot(numpy.array(loss_dual), label=\"Loss from dual\")\n",
    "            fh.ax.plot(numpy.array(loss_dual2), label=\"Loss from dual^2\")\n",
    "            fh.ax.legend()\n",
    "            fh.show()\n",
    "            fh.close()\n",
    "    \n",
    "    if stat:\n",
    "        s = {\n",
    "            \"title\": \"ADMM on dual\",\n",
    "            \"loss\": (c * (-d)).sum() / scale,\n",
    "            \"vars\": 2*m*n + m + n,\n",
    "            \"iters\": itc,\n",
    "        }\n",
    "        return p, s\n",
    "    else:\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ConvertEnd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !Convert*first_ADMM_dual_test.py*w*sehx*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !Switch*\n",
    "# !SwitchCase*\n",
    "# import font\n",
    "# from utils import *\n",
    "# from first_ADMM_dual import solve_ADMM_dual\n",
    "# !SwitchEnd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !Switch*\n",
    "fh = FigureHandler(sav=False, log=print)\n",
    "# !SwitchCase*\n",
    "# fh = FigureHandler(sav=True, disp=False, ext=\".pgf\", log=print)\n",
    "# !SwitchEnd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat = Statistics(\n",
    "    probs=[\n",
    "        ot_2d_general(\n",
    "            m=500, n=500,\n",
    "            mup_gen=samp_2d_Caffarelli(0., 0., 1., 0.),\n",
    "            nup_gen=samp_2d_Caffarelli(0., 0., 1., 2.),\n",
    "            mu_gen=val_const(),\n",
    "            nu_gen=val_const(),\n",
    "            dist=dist_2d_euc_2,\n",
    "        )\n",
    "    ],\n",
    "    merge_config=general_merge_config,\n",
    "    output_config=general_output_config,\n",
    "    prob=\"Test problems\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.test(\n",
    "    solve_ADMM_dual,\n",
    "    its=[8000],\n",
    "    rhos=[0.1],\n",
    "    alphas=[1.618],\n",
    "    epss=[1e-3],\n",
    "    fh=fh, figs={\"error\", \"loss\"},\n",
    ")\n",
    "stat.output_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.test(\n",
    "    solve_ADMM_dual,\n",
    "    its=[8000],\n",
    "    rhos=[0.1],\n",
    "    alphas=[1.618],\n",
    "    epss=[1e-3],\n",
    ")\n",
    "stat.output_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from solver_mosek import solve_mosek_interior_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.test(\n",
    "    solve_mosek_interior_point,\n",
    ")\n",
    "stat.output_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ConvertEnd*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
